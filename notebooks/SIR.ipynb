{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "# import time\n",
    "from pprint import pprint\n",
    "\n",
    "# import googlemaps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "main_dir = os.path.abspath(os.pardir)\n",
    "sys.path.insert(0, main_dir)\n",
    "from analysis.download_data import jh_git_url, all_files\n",
    "from covid_forecast.utils import data_prep as dp\n",
    "from analysis.estimate_sir_params import estimate_sir_params\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.precision = 2\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Users\\gjnet\\code_projects\\covid_forecast\n",
      "D:\\Users\\gjnet\\code_projects\\covid_forecast\\data\\raw\\\n"
     ]
    }
   ],
   "source": [
    "export_dir = os.path.join(main_dir, \"data\", \"raw\"+os.sep)\n",
    "countries_fname = \"countries.csv\"\n",
    "print(main_dir+\"\\n\"+export_dir)\n",
    "prov_state_vname = \"Province/State\"\n",
    "country_region_vname = \"Country/Region\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Open files as dataframes\n",
    "Credit to dgrechka for locations_population. Data [source](https://www.kaggle.com/dgrechka/covid19-global-forecasting-locations-population/metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'confirmed_global': 'time_series_covid19_confirmed_global.csv',\n",
      " 'deaths_global': 'time_series_covid19_deaths_global.csv',\n",
      " 'recovered_global': 'time_series_covid19_recovered_global.csv'}\n"
     ]
    }
   ],
   "source": [
    "locations_population = pd.read_csv(os.path.join(main_dir, \"data\", \"raw\", \"locations_population.csv\"))\n",
    "friendly_fnames = [file.replace(\"time_series_covid19_\", \"\").replace(\".csv\", \"\") for file in all_files]\n",
    "filename_dct = dict(zip(friendly_fnames, all_files))\n",
    "pprint(filename_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dct = dict()\n",
    "for file in filename_dct.keys():\n",
    "    df_dct[file] = pd.read_csv(jh_git_url+filename_dct[file])  # reads csv from github repo\n",
    "    exec(file+\" = df_dct['\"+file+\"']\")  # creates a reference for friendly_names\n",
    "    print(file, df_dct[file].shape)\n",
    "    display(df_dct[file].head(), df_dct[file].describe(include=\"all\"), df_dct[file].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_global.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_global[country_region_vname].drop_duplicates().to_csv(export_dir+countries_fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start timer\n",
    "# start_time = pd.to_datetime(\"now\")\n",
    "# time_fmt = \"%d/%m/%Y %H:%M:%S\"\n",
    "# print(\"INFO: start time\", start_time.strftime(time_fmt))\n",
    "\n",
    "# # Filling missing province/state where possible\n",
    "# gmaps = googlemaps.Client(key=os.getenv(\"gmaps_api_key\"))\n",
    "\n",
    "# match_keys = [\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"]\n",
    "# fillna_keys = [\"Province/State\", \"Country/Region\"]\n",
    "# loc_admin_long_vname = \"long_name\"\n",
    "\n",
    "# # Start with the first df with missing province/state values\n",
    "# temp_df = confirmed_global[match_keys][confirmed_global[prov_state_vname].isna()].copy()\n",
    "\n",
    "# for i in temp_df.index:\n",
    "#     row = temp_df.loc[i]\n",
    "\n",
    "#     # Look up an address with reverse geocoding\n",
    "#     try:\n",
    "#         target_loc = gmaps.reverse_geocode((row[\"Lat\"], row[\"Long\"]))[0]['address_components']\n",
    "#     except IndexError:\n",
    "#         continue\n",
    "#     admin_ind = dp.find_admin_loc(target_loc)\n",
    "#     if admin_ind is not None:\n",
    "#         temp_df.loc[i, prov_state_vname] = target_loc[dp.find_admin_loc(target_loc)][loc_admin_long_vname]\n",
    "    \n",
    "#     # Fill missing with country/region\n",
    "#     temp_df[prov_state_vname] = temp_df[prov_state_vname].fillna(temp_df[country_region_vname])\n",
    "    \n",
    "#     # Gmaps anti-throttling tactic\n",
    "#     time.sleep(1)  # wait 1 second before the next iteration\n",
    "\n",
    "# # Fillna missing values\n",
    "# for df in df_dct.keys():\n",
    "#     df_dct[df][fillna_keys] = confirmed_global[fillna_keys].fillna(temp_df[fillna_keys])\n",
    "\n",
    "# # Finish time\n",
    "# finish_time = pd.to_datetime(\"now\")\n",
    "# elapsed_time_min = round((finish_time-start_time).total_seconds()/60, 2)\n",
    "# print(\"INFO: finished. This took\", elapsed_time_min, \"minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: population data from Rafa's ARIMA and plug this in s_0\n",
    "# https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide\n",
    "\n",
    "# TODO: remove head of country row until you find a value > 0 (use numpy) - remove_initia_zeros = np.trim_zeros(data_[variable]).__len__()\n",
    "\n",
    "# TODO: return beta, and gamma\n",
    "\n",
    "# TODO: don't return figure\n",
    "\n",
    "# TODO: SIR: pass prepared dataframes instead of downloading again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dct = dp.bulk_reduce_mem(df_dct)\n",
    "# population_df = population_df.pipe(dp.reduce_mem)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIR\n",
    "[Source code](https://scipython.com/book/chapter-8-scipy/additional-examples/the-sir-epidemic-model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total population, N.\n",
    "# N = 1000\n",
    "\n",
    "# # Initial number of infected and recovered individuals, I0 and R0.\n",
    "# I0, R0 = 1, 0\n",
    "\n",
    "# # Everyone else, S0, is susceptible to infection initially.\n",
    "# S0 = N - I0 - R0\n",
    "\n",
    "# # Contact rate (aka beta), and mean recovery rate aka (gamma) both (in 1/days).\n",
    "# beta, gamma = 0.2, 1./10\n",
    "\n",
    "# # A grid of time points (in days)\n",
    "# days = 160\n",
    "# t = np.linspace(0, days, days)\n",
    "\n",
    "# # Initial conditions vector\n",
    "# y0 = S0, I0, R0\n",
    "# # Integrate the SIR equations over the time grid, t.\n",
    "# ret = odeint(dp.deriv, y0, t, args=(N, beta, gamma))\n",
    "# S, I, R = ret.T\n",
    "\n",
    "# # Plot the data on three separate curves for S(t), I(t) and R(t)\n",
    "# fig = plt.figure(facecolor='w')\n",
    "# ax = fig.add_subplot(111, axisbelow=True)\n",
    "# ax.plot(t, S/1000, 'b', alpha=0.5, lw=2, label='Susceptible')\n",
    "# ax.plot(t, I/1000, 'r', alpha=0.5, lw=2, label='Infected')\n",
    "# ax.plot(t, R/1000, 'g', alpha=0.5, lw=2, label='Recovered with immunity')\n",
    "# ax.set_facecolor('#dddddd')\n",
    "# ax.set_xlabel('Time /days')\n",
    "# ax.set_ylabel('Number (1000s)')\n",
    "# ax.set_ylim(0,1.2)\n",
    "# ax.yaxis.set_tick_params(length=0)\n",
    "# ax.xaxis.set_tick_params(length=0)\n",
    "# ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
    "# legend = ax.legend()\n",
    "# legend.get_frame().set_alpha(0.5)\n",
    "# for spine in ('top', 'right', 'bottom', 'left'):\n",
    "#     ax.spines[spine].set_visible(False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating SIR beta and gamma parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.estimate_sir_params import estimate_sir_params\n",
    "estimate_sir_params(countries=confirmed_global[country_region_vname].drop_duplicates())  # .iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
